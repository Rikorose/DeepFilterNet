[train]
seed = 43
device = 
model = deepfilternet2
jit = true
mask_only = false
df_only = false
batch_size = 96
batch_size_eval = 128
num_workers = 16
max_sample_len_s = 3.0
p_atten_lim = 0.0
p_reverb = 0.2
overfit = false
start_eval = true
max_epochs = 100
log_freq = 50
detect_anomaly = false
validation_criteria = loss
validation_criteria_rule = min
early_stopping_patience = 10
global_ds_sampling_f = 1
num_prefetch_batches = 8
dataloader_snrs = -5,0,5,10,20,40
train_autocast = False
n_checkpoint_history = 5
n_best_checkpoint_history = 10
batch_size_scheduling = 

[df]
sr = 48000
fft_size = 960
hop_size = 480
nb_erb = 32
nb_df = 96
norm_tau = 1
lsnr_max = 35
lsnr_min = -15
min_nb_erb_freqs = 2

[deepfilternet]
conv_lookahead = 2
conv_ch = 64
conv_depthwise = True
emb_hidden_dim = 512
emb_num_layers = 3
gru_groups = 8
linear_groups = 8
conv_dec_mode = transposed
convt_depthwise = True
mask_pf = False
df_order = 5
df_lookahead = 2
df_hidden_dim = 512
df_num_layers = 2
dfop_method = real_unfold
group_shuffle = False
conv_kernel = 2,3

[localsnrloss]
factor = 1e-3

[maskloss]
factor = 0
mask = iam
gamma = 0.6
gamma_pred = 0.6
f_under = 1

[spectralloss]
factor_magnitude = 1000
factor_complex = 1000
gamma = 0.3

[dfalphaloss]
factor = 0.0

[multiresspecloss]
factor = 500
factor_complex = 500
gamma = 0.3
fft_sizes = 256,512,1024

[optim]
lr = 0.001
momentum = 0
weight_decay = 1e-12
weight_decay_end = 0.05
optimizer = adamw
lr_min = 1e-06
lr_warmup = 0.0001
warmup_epochs = 3
lr_cycle_mul = 1.0
lr_cycle_decay = 0.5
lr_cycle_limit = 1
lr_update_per_epoch = False
lr_cycle_epochs = -1

[sdrloss]
factor = 0.0
segmental_ws = 0

